{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积神经网络进行图像识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积神经网络的图像识别模仿了人脑的视觉处理机制，采用分级提取特征的原理，每一级的特征均由网络学习提取，识别效果优于人工选取特征的算法\n",
    "例如：在人脸识别过程中，最底层特征基本是各个方向上的边缘，越往上的神经层越能提取出人脸的局部特征，最上层由不同的高级特征组合成人脸的图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积：将过滤器每个格子的权重值与图片对应的像素值相乘并累加，得到的值就是特征图中的一个像素值\n",
    "    相比传统全连接的神经网络，能有效减少权重数\n",
    "    传统：100*100 图片每个像素点都连接到每一个隐含层的节点上，如果隐含层的节点数为 10000, 那么连接的权重总数为 10^8 个\n",
    "    卷积: 10*10 过滤器对原图 100*100 图片 进行卷积时，该过滤器不断滑动对应生成一张特征图，即一个过滤器(100个权重值)可对应一张特征图，如果有 100 张特征图，则一共只需要 10^4 个权重值\n",
    "    所以在一个隐含层的情况下，卷积神经网络的权重数目可以减小至全连接神经网络权重数目的万分之一，大大减少计算量，提高计算效率\n",
    "实际训练中，第一层的每一个过滤器的权重值会不断地被更新优化，使得每个过滤器的可视化纹理模式基本上反映了各个方向上的边缘特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "池化：降低数据的维度，过程就是 下采样，　特征图 8*8, 池化窗口 4*4, 采样结束后成 2*2 的池化特征图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,),)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST('data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    '''\n",
    "    2d: 2维图片处理\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # c1卷积层 (1, 6, 5)输入 1 张灰度图, 输出 6 张特征图, 过滤器 5*5\n",
    "        self.c1 = nn.Conv2d(1, 6, 5)\n",
    "        # c3卷积层 (6, 16, 5)输入 6 张灰度图, 输出 16 张特征图, 过滤器 5*5\n",
    "        self.c3 = nn.Conv2d(6, 16, 5)\n",
    "        # fc1全连接层 池化层 S4 中的所有特征点 16*4*4, 全连接到 120 个点\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        # fc2全连接层 120 全连接到 84 个点\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # fc3全连接层 84 全连接到 10 个输出\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # max_pool2d 池化, 池化核 2*2\n",
    "        x = F.max_pool2d(F.relu(self.c1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.c3(x)), 2)\n",
    "        # 转化一维向量\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "    def num_flat_features(self, x):\n",
    "        # 计算 x 特征点的总数\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "# 使用 DataLoader 来加载数据, batch_size 表示一次加载的数量, shuffle遍历不同批次的数据打乱顺序,num_workers 使用 2 个子进程加载数据\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, model, epochs=1, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # 带动量的随机梯度下降法\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if i % 1000 == 999:\n",
    "                print('[Epoch:%d, Batch:%5d] Loss: %.3f' % (epoch+1, i+1, running_loss/1000))\n",
    "                running_loss = 0.0\n",
    "    \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:1, Batch: 1000] Loss: 1.116\n",
      "[Epoch:1, Batch: 2000] Loss: 0.281\n",
      "[Epoch:1, Batch: 3000] Loss: 0.217\n",
      "[Epoch:1, Batch: 4000] Loss: 0.170\n",
      "[Epoch:1, Batch: 5000] Loss: 0.127\n",
      "[Epoch:1, Batch: 6000] Loss: 0.115\n",
      "[Epoch:1, Batch: 7000] Loss: 0.112\n",
      "[Epoch:1, Batch: 8000] Loss: 0.100\n",
      "[Epoch:1, Batch: 9000] Loss: 0.098\n",
      "[Epoch:1, Batch:10000] Loss: 0.109\n",
      "[Epoch:1, Batch:11000] Loss: 0.102\n",
      "[Epoch:1, Batch:12000] Loss: 0.092\n",
      "[Epoch:1, Batch:13000] Loss: 0.090\n",
      "[Epoch:1, Batch:14000] Loss: 0.079\n",
      "[Epoch:1, Batch:15000] Loss: 0.076\n",
      "[Epoch:2, Batch: 1000] Loss: 0.067\n",
      "[Epoch:2, Batch: 2000] Loss: 0.056\n",
      "[Epoch:2, Batch: 3000] Loss: 0.061\n",
      "[Epoch:2, Batch: 4000] Loss: 0.072\n",
      "[Epoch:2, Batch: 5000] Loss: 0.066\n",
      "[Epoch:2, Batch: 6000] Loss: 0.064\n",
      "[Epoch:2, Batch: 7000] Loss: 0.056\n",
      "[Epoch:2, Batch: 8000] Loss: 0.068\n",
      "[Epoch:2, Batch: 9000] Loss: 0.054\n",
      "[Epoch:2, Batch:10000] Loss: 0.060\n",
      "[Epoch:2, Batch:11000] Loss: 0.043\n",
      "[Epoch:2, Batch:12000] Loss: 0.037\n",
      "[Epoch:2, Batch:13000] Loss: 0.059\n",
      "[Epoch:2, Batch:14000] Loss: 0.060\n",
      "[Epoch:2, Batch:15000] Loss: 0.056\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(trainloader, model, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_param(model, path):\n",
    "    if os.path.exists(path):\n",
    "        model.load_state_dict(torch.load(path))\n",
    "\n",
    "def save_param(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of LeNet(\n",
       "  (c1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (c3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(testloader, model):\n",
    "    # 正确的总数\n",
    "    correct = 0\n",
    "    # 预测的总数\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        image, labels = data\n",
    "        outputs = model(image)\n",
    "        _, perdicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (perdicted == labels).sum()\n",
    "    print('Accuracy on the test set: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 98 %\n"
     ]
    }
   ],
   "source": [
    "test(testloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'data/model_num_image.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
